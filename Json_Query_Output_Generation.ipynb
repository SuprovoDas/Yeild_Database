{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a92de3a",
   "metadata": {},
   "source": [
    "## Read JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d36755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_title: Dataset for Rabi Wheat in Bihar\n",
      "feature_set: [{'feature_details': {'feature_name': 'Weighted Yield', 'feature_data_category': 'AREA_PRODUCTION_YIELD_ITEM', 'feature_data_location': 'STATE', 'feature_spatial_aggregation': 'DISTRICT_TO_STATE_SWA', 'feature_temporal_interval': 'SEASON', 'feature_temporal_aggregation': 'NA', 'is_target': 'true', 'temporal_interval_items': ''}}, {'feature_details': {'feature_name': 'TRF', 'feature_data_category': 'LOCATION_RAINFALL', 'feature_data_location': 'STATE', 'feature_spatial_aggregation': 'DISTRICT_TO_STATE_SWA', 'feature_temporal_interval': 'MONTH', 'feature_temporal_aggregation': 'DAILY_TO_MONTHLY_AVG', 'is_target': 'false', 'temporal_interval_items': [{'range_start': 'MAY', 'range_end': 'JUNE', 'base_year': 'SEASON_START'}, {'range_start': 'OCTOBER', 'range_end': 'DECEMBER', 'base_year': 'SEASON_START'}, {'range_start': 'FEBRUARY', 'range_end': 'FEBRUARY', 'base_year': 'SEASON_END'}]}}, {'feature_details': {'feature_name': 'AMXT', 'feature_data_category': 'LOCATION_TEMPERATURE', 'feature_data_location': 'STATE', 'feature_spatial_aggregation': 'DISTRICT_TO_STATE_SWA', 'feature_temporal_interval': 'MONTH', 'feature_temporal_aggregation': 'DAILY_TO_MONTHLY_AVG', 'is_target': 'false', 'temporal_interval_items': [{'range_start': 'MAY', 'range_end': 'JULY', 'base_year': 'SEASON_START'}, {'range_start': 'OCTOBER', 'range_end': 'MARCH', 'base_year': 'SEASON_END'}]}}]\n",
      "crop: wheat\n",
      "season: Rabi\n",
      "state: Bihar\n",
      "start_year: 2000\n",
      "end_year: 2022\n",
      "apy_collection: 243\n",
      "temperature_collection: 100\n",
      "rainfall_collection: 243\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('C:/Users/Dell/Downloads/Modified_Dataset_Generation_JSON.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "# view the json file's key-value pairs\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa6040",
   "metadata": {},
   "source": [
    "## Month Range Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c532e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Range of Months for the columns\n",
    "import datetime\n",
    "\n",
    "def month_name_to_number(month_name):\n",
    "    try:\n",
    "        # Capitalize the first letter only, since strptime expects \"January\", not \"JANUARY\"\n",
    "        dt = datetime.datetime.strptime(month_name.capitalize(), \"%B\")\n",
    "        return dt.month\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def get_months_between(start_num, end_num):\n",
    "    if start_num <= end_num:\n",
    "        return [(m) for m in range(start_num, end_num + 1)]\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b3cbd",
   "metadata": {},
   "source": [
    "## Feature Extraction (Practice - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea180092",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = []\n",
    "feature_data_category = []\n",
    "month_range = []\n",
    "for feature in data[\"feature_set\"]:\n",
    "    details = feature[\"feature_details\"]\n",
    "    feature_name.append(details[\"feature_name\"])\n",
    "    feature_data_category.append(details[\"feature_data_category\"])\n",
    "    range_pairs = []\n",
    "    items = details.get(\"temporal_interval_items\", [])\n",
    "    if isinstance(items, list):\n",
    "        for interval in items:\n",
    "            start_num = month_name_to_number(interval[\"range_start\"])\n",
    "            #print(interval[\"range_start\"])\n",
    "            end_num = month_name_to_number(interval[\"range_end\"])\n",
    "            #print(end_num)\n",
    "            range_pairs.extend(get_months_between(start_num,end_num))\n",
    "    month_range.append(range_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6793923",
   "metadata": {},
   "source": [
    "## Import Python Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8897ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypika import Query, Table, Field, functions as fn\n",
    "from pypika.terms import Case\n",
    "from pypika.enums import Order\n",
    "from pypika.functions import Extract, Sum, Max, Avg, Date\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15367adf",
   "metadata": {},
   "source": [
    "## Weighted Yeild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685c49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Subquery: final_aggregated ---\n",
    "def apy_yeild(feature_data_category,feature_name,month_range,data):\n",
    "    apy = Table(feature_data_category, schema=\"npcyf_schema\")\n",
    "    district = Table(\"DISTRICT\", schema=\"npcyf_schema\")\n",
    "    state = Table(\"STATE\", schema=\"npcyf_schema\")\n",
    "    crop = Table(\"CROP\", schema=\"npcyf_schema\")\n",
    "    season = Table(\"SEASON\", schema=\"npcyf_schema\")\n",
    "    sub_apy = (\n",
    "        Query.from_(apy)\n",
    "        .join(district).on(district.district_id == apy.location_id)\n",
    "        .join(state).on(district.state_id == state.state_id)\n",
    "        .join(crop).on(apy.crop_id == crop.crop_id)\n",
    "        .join(season).on(apy.season_id == season.season_id)\n",
    "        .select(\n",
    "            state.state_name,\n",
    "            district.district_name,\n",
    "            apy.location_id,\n",
    "            crop.crop_name,\n",
    "            season.season_name,\n",
    "            apy.apy_item_interval_start,\n",
    "            apy.apy_data_collection_id,\n",
    "            Max(Case().when(apy.apy_component == 'YIELD', apy.apy_item_value)).as_('yield'),\n",
    "            Max(Case().when(apy.apy_component == 'CROPPED_AREA', apy.apy_item_value)).as_('cropped_area')\n",
    "        )\n",
    "        .where(\n",
    "            (state.state_name == data['state'].lower()) &\n",
    "            (season.season_name == data['season'].lower()) &\n",
    "            (crop.crop_name == data['crop'].lower()) &\n",
    "            (apy.apy_data_collection_id == data[\"apy_collection\"]) &\n",
    "            (apy.location_type == 'DISTRICT') &\n",
    "            (apy.apy_item_interval_start >= int(data['start_year'])) &\n",
    "            (apy.apy_item_interval_start <= int(data['end_year']))\n",
    "\n",
    "        )\n",
    "        .groupby(\n",
    "            state.state_name,\n",
    "            district.district_name,\n",
    "            apy.location_id,\n",
    "            crop.crop_name,\n",
    "            season.season_name,\n",
    "            apy.apy_item_interval_start,\n",
    "            apy.apy_data_collection_id\n",
    "    ))\n",
    "    final_aggr = Table(\"final_aggregated\")\n",
    "\n",
    "    return (\n",
    "        Query.from_(sub_apy.as_('final_aggregated'))\n",
    "        .select(\n",
    "            final_aggr.state_name,\n",
    "            final_aggr.crop_name,\n",
    "            final_aggr.season_name,\n",
    "            final_aggr.apy_item_interval_start.as_('year'),\n",
    "            Case()\n",
    "            .when(Sum(final_aggr.cropped_area) != 0,\n",
    "                fn.Sum(final_aggr['yield'] * final_aggr.cropped_area) / Sum(final_aggr.cropped_area))\n",
    "            .else_(None)\n",
    "            .as_(feature_name)\n",
    "        )\n",
    "        .groupby(\n",
    "            final_aggr.state_name,\n",
    "            final_aggr.crop_name,\n",
    "            final_aggr.season_name,\n",
    "            final_aggr.apy_item_interval_start,\n",
    "            final_aggr.apy_data_collection_id\n",
    "    )).as_('g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1874981",
   "metadata": {},
   "source": [
    "## Max Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7170292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_rainfall(feature_data_category,alias_prefix,month_range,data):\n",
    "    rain = Table(feature_data_category, schema=\"npcyf_schema\")\n",
    "    district = Table(\"DISTRICT\", schema=\"npcyf_schema\")\n",
    "    state = Table(\"STATE\", schema=\"npcyf_schema\")\n",
    "    rain_data = (\n",
    "        Query.from_(rain)\n",
    "        .join(district).on(rain.location_id == district.district_id)\n",
    "        .join(state).on(district.state_id == state.state_id)\n",
    "        .select(\n",
    "            state.state_name,\n",
    "            Extract('year', rain.rainfall_recorded_date).as_('year'),\n",
    "            Extract('month', rain.rainfall_recorded_date).as_('month'),\n",
    "            Extract('day', rain.rainfall_recorded_date).as_('day'),\n",
    "            rain.rainfall_value\n",
    "        )\n",
    "        .where(\n",
    "            (state.state_name == data['state'].lower()) &\n",
    "            (rain.location_type == 'DISTRICT') &\n",
    "            (rain.rainfall_data_collection_id == data[\"rainfall_collection\"]) &\n",
    "            (rain.rainfall_recorded_year >= data[\"start_year\"])&\n",
    "            (rain.rainfall_recorded_year <= data[\"end_year\"]) &\n",
    "            Extract('month', rain.rainfall_recorded_date).isin(range_pairs)\n",
    "        )\n",
    "    ).as_('rainfall_data')\n",
    "\n",
    "    rainfall_expressions = []\n",
    "    for month in month_range:\n",
    "        label = f\"{alias_prefix}_{month}\"\n",
    "        condition1 = (rain_data.month == month)\n",
    "        expr = Sum(Case().when(condition1, rain_data.rainfall_value).else_(0)).as_(label)\n",
    "        rainfall_expressions.append(expr)\n",
    "\n",
    "    # Build final query\n",
    "    return (\n",
    "        Query.from_(rain_data)\n",
    "        .select(\n",
    "            rain_data.state_name,\n",
    "            rain_data.year,\n",
    "            *rainfall_expressions\n",
    "        )\n",
    "        .groupby(rain_data.state_name, rain_data.year)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917e8a5",
   "metadata": {},
   "source": [
    "## Average Monthly Max Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0009df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_max_temperature(feature_data_category, alias_prefix,month_range,data):\n",
    "    temp = Table(feature_data_category, schema=\"npcyf_schema\")\n",
    "    district = Table(\"DISTRICT\", schema=\"npcyf_schema\")\n",
    "    state = Table(\"STATE\", schema=\"npcyf_schema\")\n",
    "    sub_temp = (\n",
    "        Query.from_(temp)\n",
    "        .join(district).on(temp.location_id == district.district_id)\n",
    "        .join(state).on(district.state_id == state.state_id)\n",
    "        .select(\n",
    "            state.state_name,\n",
    "            Date(temp.temperature_recorded_date).as_('date'),\n",
    "            Extract('year', temp.temperature_recorded_date).as_('year'),\n",
    "            Extract('month', temp.temperature_recorded_date).as_('month'),\n",
    "            Extract('day', temp.temperature_recorded_date).as_('day'),\n",
    "            Avg(temp.temperature_value).as_('avg_temp_per_day')\n",
    "        )\n",
    "        .where(\n",
    "            (temp.location_type == 'DISTRICT') &\n",
    "            (state.state_name == data[\"state\"].lower()) &\n",
    "            (temp.temperature_data_collection_id == int(data['temperature_collection'])) &\n",
    "            (temp.temperature_recorded_year >= data[\"start_year\"])&\n",
    "            (temp.temperature_recorded_year <= data[\"end_year\"]) &\n",
    "            Extract('month', temp.temperature_recorded_date).isin(month_range)\n",
    "        )\n",
    "        .groupby(state.state_name, Date(temp.temperature_recorded_date))\n",
    "    ).as_(f'daily_state_temp_{alias_prefix}')\n",
    "\n",
    "    temperate_expressions = []\n",
    "    for month in month_range:\n",
    "        label = f\"{alias_prefix}_{month}\"\n",
    "        condition = (sub_temp.month == month)\n",
    "        expr = Avg(Case().when(condition, sub_temp.avg_temp_per_day)).as_(label)\n",
    "        temperate_expressions.append(expr)\n",
    "    return (\n",
    "        Query.from_(sub_temp)\n",
    "        .select(\n",
    "            sub_temp.state_name,\n",
    "            sub_temp.year,\n",
    "            *temperate_expressions\n",
    "        ).groupby(sub_temp.state_name, sub_temp.year)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e24771",
   "metadata": {},
   "source": [
    "## Unkown Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624c895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_default(feature_data_category,feature_name,month_range,data):\n",
    "    print(f\"Unknown feature category: {feature_name}\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e267a",
   "metadata": {},
   "source": [
    "## Case Function for Selecting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8dcbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "category_handlers = {\n",
    "    \"AREA_PRODUCTION_YIELD_ITEM\": apy_yeild,\n",
    "    \"LOCATION_RAINFALL\": max_rainfall,\n",
    "    \"LOCATION_TEMPERATURE\": avg_max_temperature\n",
    "}\n",
    "for feature in data[\"feature_set\"]:\n",
    "    details = feature[\"feature_details\"]\n",
    "    feature_name = details[\"feature_name\"]\n",
    "    feature_data_category = details[\"feature_data_category\"]\n",
    "    range_pairs = []\n",
    "    items = details.get(\"temporal_interval_items\", [])\n",
    "    if isinstance(items, list):\n",
    "        for interval in items:\n",
    "            start_num = month_name_to_number(interval[\"range_start\"])\n",
    "            #print(interval[\"range_start\"])\n",
    "            end_num = month_name_to_number(interval[\"range_end\"])\n",
    "            #print(end_num)\n",
    "            range_pairs.extend(get_months_between(start_num,end_num))\n",
    "    month_range.append(range_pairs)\n",
    "    handler = category_handlers.get(details[\"feature_data_category\"], handle_default)\n",
    "    if handler is not handle_default:\n",
    "        output[feature_name] = handler(feature_data_category, feature_name, range_pairs, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af369fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"final_aggregated\".\"state_name\",\"final_aggregated\".\"crop_name\",\"final_aggregated\".\"season_name\",\"final_aggregated\".\"apy_item_interval_start\" \"year\",CASE WHEN SUM(\"final_aggregated\".\"cropped_area\")<>0 THEN SUM(\"final_aggregated\".\"yield\"*\"final_aggregated\".\"cropped_area\")/SUM(\"final_aggregated\".\"cropped_area\") ELSE NULL END \"Weighted Yield\" FROM (SELECT \"STATE\".\"state_name\",\"DISTRICT\".\"district_name\",\"AREA_PRODUCTION_YIELD_ITEM\".\"location_id\",\"CROP\".\"crop_name\",\"SEASON\".\"season_name\",\"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_interval_start\",\"AREA_PRODUCTION_YIELD_ITEM\".\"apy_data_collection_id\",MAX(CASE WHEN \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_component\"='YIELD' THEN \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_value\" END) \"yield\",MAX(CASE WHEN \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_component\"='CROPPED_AREA' THEN \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_value\" END) \"cropped_area\" FROM \"npcyf_schema\".\"AREA_PRODUCTION_YIELD_ITEM\" JOIN \"npcyf_schema\".\"DISTRICT\" ON \"DISTRICT\".\"district_id\"=\"AREA_PRODUCTION_YIELD_ITEM\".\"location_id\" JOIN \"npcyf_schema\".\"STATE\" ON \"DISTRICT\".\"state_id\"=\"STATE\".\"state_id\" JOIN \"npcyf_schema\".\"CROP\" ON \"AREA_PRODUCTION_YIELD_ITEM\".\"crop_id\"=\"CROP\".\"crop_id\" JOIN \"npcyf_schema\".\"SEASON\" ON \"AREA_PRODUCTION_YIELD_ITEM\".\"season_id\"=\"SEASON\".\"season_id\" WHERE \"STATE\".\"state_name\"='bihar' AND \"SEASON\".\"season_name\"='rabi' AND \"CROP\".\"crop_name\"='wheat' AND \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_data_collection_id\"='243' AND \"AREA_PRODUCTION_YIELD_ITEM\".\"location_type\"='DISTRICT' AND \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_interval_start\">=2000 AND \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_interval_start\"<=2022 GROUP BY \"STATE\".\"state_name\",\"DISTRICT\".\"district_name\",\"AREA_PRODUCTION_YIELD_ITEM\".\"location_id\",\"CROP\".\"crop_name\",\"SEASON\".\"season_name\",\"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_interval_start\",\"AREA_PRODUCTION_YIELD_ITEM\".\"apy_data_collection_id\") \"final_aggregated\" GROUP BY \"final_aggregated\".\"state_name\",\"final_aggregated\".\"crop_name\",\"final_aggregated\".\"season_name\",\"final_aggregated\".\"apy_item_interval_start\",\"final_aggregated\".\"apy_data_collection_id\"\n",
      "SELECT \"rainfall_data\".\"state_name\",\"rainfall_data\".\"year\",SUM(CASE WHEN \"rainfall_data\".\"month\"=5 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_5\",SUM(CASE WHEN \"rainfall_data\".\"month\"=6 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_6\",SUM(CASE WHEN \"rainfall_data\".\"month\"=10 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_10\",SUM(CASE WHEN \"rainfall_data\".\"month\"=11 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_11\",SUM(CASE WHEN \"rainfall_data\".\"month\"=12 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_12\",SUM(CASE WHEN \"rainfall_data\".\"month\"=2 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_2\" FROM (SELECT \"STATE\".\"state_name\",EXTRACT(year FROM \"LOCATION_RAINFALL\".\"rainfall_recorded_date\") \"year\",EXTRACT(month FROM \"LOCATION_RAINFALL\".\"rainfall_recorded_date\") \"month\",EXTRACT(day FROM \"LOCATION_RAINFALL\".\"rainfall_recorded_date\") \"day\",\"LOCATION_RAINFALL\".\"rainfall_value\" FROM \"npcyf_schema\".\"LOCATION_RAINFALL\" JOIN \"npcyf_schema\".\"DISTRICT\" ON \"LOCATION_RAINFALL\".\"location_id\"=\"DISTRICT\".\"district_id\" JOIN \"npcyf_schema\".\"STATE\" ON \"DISTRICT\".\"state_id\"=\"STATE\".\"state_id\" WHERE \"STATE\".\"state_name\"='bihar' AND \"LOCATION_RAINFALL\".\"location_type\"='DISTRICT' AND \"LOCATION_RAINFALL\".\"rainfall_data_collection_id\"='243' AND \"LOCATION_RAINFALL\".\"rainfall_recorded_year\">='2000' AND \"LOCATION_RAINFALL\".\"rainfall_recorded_year\"<='2022' AND EXTRACT(month FROM \"LOCATION_RAINFALL\".\"rainfall_recorded_date\") IN (5,6,10,11,12,2)) \"rainfall_data\" GROUP BY \"rainfall_data\".\"state_name\",\"rainfall_data\".\"year\"\n",
      "SELECT \"daily_state_temp_AMXT\".\"state_name\",\"daily_state_temp_AMXT\".\"year\",AVG(CASE WHEN \"daily_state_temp_AMXT\".\"month\"=5 THEN \"daily_state_temp_AMXT\".\"avg_temp_per_day\" END) \"AMXT_5\",AVG(CASE WHEN \"daily_state_temp_AMXT\".\"month\"=6 THEN \"daily_state_temp_AMXT\".\"avg_temp_per_day\" END) \"AMXT_6\",AVG(CASE WHEN \"daily_state_temp_AMXT\".\"month\"=7 THEN \"daily_state_temp_AMXT\".\"avg_temp_per_day\" END) \"AMXT_7\" FROM (SELECT \"STATE\".\"state_name\",DATE(\"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") \"date\",EXTRACT(year FROM \"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") \"year\",EXTRACT(month FROM \"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") \"month\",EXTRACT(day FROM \"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") \"day\",AVG(\"LOCATION_TEMPERATURE\".\"temperature_value\") \"avg_temp_per_day\" FROM \"npcyf_schema\".\"LOCATION_TEMPERATURE\" JOIN \"npcyf_schema\".\"DISTRICT\" ON \"LOCATION_TEMPERATURE\".\"location_id\"=\"DISTRICT\".\"district_id\" JOIN \"npcyf_schema\".\"STATE\" ON \"DISTRICT\".\"state_id\"=\"STATE\".\"state_id\" WHERE \"LOCATION_TEMPERATURE\".\"location_type\"='DISTRICT' AND \"STATE\".\"state_name\"='bihar' AND \"LOCATION_TEMPERATURE\".\"temperature_data_collection_id\"=100 AND \"LOCATION_TEMPERATURE\".\"temperature_recorded_year\">='2000' AND \"LOCATION_TEMPERATURE\".\"temperature_recorded_year\"<='2022' AND EXTRACT(month FROM \"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") IN (5,6,7) GROUP BY \"STATE\".\"state_name\",DATE(\"LOCATION_TEMPERATURE\".\"temperature_recorded_date\")) \"daily_state_temp_AMXT\" GROUP BY \"daily_state_temp_AMXT\".\"state_name\",\"daily_state_temp_AMXT\".\"year\"\n"
     ]
    }
   ],
   "source": [
    "for name, result in output.items():\n",
    "    print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4281784a",
   "metadata": {},
   "source": [
    "## Final Join and Generate the Full Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c649aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate table aliases\n",
    "feature_names = list(output.keys())\n",
    "tables = [Table(alias) for alias in feature_names]\n",
    "tables\n",
    "if not tables:\n",
    "    raise RuntimeError(\"Stopping execution: condition failed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c86e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Query.from_(tables[0])\n",
    "\n",
    "# Step 3: Join the remaining tables on state_name and year\n",
    "for t in tables[1:]:\n",
    "    q = q.join(t).on(\n",
    "        (tables[0].state_name == t.state_name) &\n",
    "        (tables[0].year == t.year)\n",
    "    )\n",
    "\n",
    "# Step 4: Select all columns (or specify if needed)\n",
    "for t in tables:\n",
    "    q = q.select(*(t.star,))  # selects all columns from each table\n",
    "\n",
    "# Step 5: Get SQL (just the SELECT... FROM... JOIN part)\n",
    "main_join_sql = q.get_sql()\n",
    "\n",
    "# Step 6: Wrap the original subqueries as CTEs\n",
    "cte_sql = \"WITH\\n\" + \",\\n\".join(\n",
    "    f'\"{table_name}\" AS (\\n{output[table_name]}\\n)' for table_name  in feature_names\n",
    ")\n",
    "\n",
    "# Step 7: Final full SQL\n",
    "full_sql = f\"{cte_sql}\\n{main_join_sql}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9c432",
   "metadata": {},
   "source": [
    "#### Save the SQL query as sql file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce2b797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH\n",
      "\"Weighted Yield\" AS (\n",
      "SELECT \"final_aggregated\".\"state_name\",\"final_aggregated\".\"crop_name\",\"final_aggregated\".\"season_name\",\"final_aggregated\".\"apy_item_interval_start\" \"year\",CASE WHEN SUM(\"final_aggregated\".\"cropped_area\")<>0 THEN SUM(\"final_aggregated\".\"yield\"*\"final_aggregated\".\"cropped_area\")/SUM(\"final_aggregated\".\"cropped_area\") ELSE NULL END \"Weighted Yield\" FROM (SELECT \"STATE\".\"state_name\",\"DISTRICT\".\"district_name\",\"AREA_PRODUCTION_YIELD_ITEM\".\"location_id\",\"CROP\".\"crop_name\",\"SEASON\".\"season_name\",\"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_interval_start\",\"AREA_PRODUCTION_YIELD_ITEM\".\"apy_data_collection_id\",MAX(CASE WHEN \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_component\"='YIELD' THEN \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_value\" END) \"yield\",MAX(CASE WHEN \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_component\"='CROPPED_AREA' THEN \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_value\" END) \"cropped_area\" FROM \"npcyf_schema\".\"AREA_PRODUCTION_YIELD_ITEM\" JOIN \"npcyf_schema\".\"DISTRICT\" ON \"DISTRICT\".\"district_id\"=\"AREA_PRODUCTION_YIELD_ITEM\".\"location_id\" JOIN \"npcyf_schema\".\"STATE\" ON \"DISTRICT\".\"state_id\"=\"STATE\".\"state_id\" JOIN \"npcyf_schema\".\"CROP\" ON \"AREA_PRODUCTION_YIELD_ITEM\".\"crop_id\"=\"CROP\".\"crop_id\" JOIN \"npcyf_schema\".\"SEASON\" ON \"AREA_PRODUCTION_YIELD_ITEM\".\"season_id\"=\"SEASON\".\"season_id\" WHERE \"STATE\".\"state_name\"='bihar' AND \"SEASON\".\"season_name\"='rabi' AND \"CROP\".\"crop_name\"='wheat' AND \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_data_collection_id\"='243' AND \"AREA_PRODUCTION_YIELD_ITEM\".\"location_type\"='DISTRICT' AND \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_interval_start\">=2000 AND \"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_interval_start\"<=2022 GROUP BY \"STATE\".\"state_name\",\"DISTRICT\".\"district_name\",\"AREA_PRODUCTION_YIELD_ITEM\".\"location_id\",\"CROP\".\"crop_name\",\"SEASON\".\"season_name\",\"AREA_PRODUCTION_YIELD_ITEM\".\"apy_item_interval_start\",\"AREA_PRODUCTION_YIELD_ITEM\".\"apy_data_collection_id\") \"final_aggregated\" GROUP BY \"final_aggregated\".\"state_name\",\"final_aggregated\".\"crop_name\",\"final_aggregated\".\"season_name\",\"final_aggregated\".\"apy_item_interval_start\",\"final_aggregated\".\"apy_data_collection_id\"\n",
      "),\n",
      "\"TRF\" AS (\n",
      "SELECT \"rainfall_data\".\"state_name\",\"rainfall_data\".\"year\",SUM(CASE WHEN \"rainfall_data\".\"month\"=5 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_5\",SUM(CASE WHEN \"rainfall_data\".\"month\"=6 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_6\",SUM(CASE WHEN \"rainfall_data\".\"month\"=10 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_10\",SUM(CASE WHEN \"rainfall_data\".\"month\"=11 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_11\",SUM(CASE WHEN \"rainfall_data\".\"month\"=12 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_12\",SUM(CASE WHEN \"rainfall_data\".\"month\"=2 THEN \"rainfall_data\".\"rainfall_value\" ELSE 0 END) \"TRF_2\" FROM (SELECT \"STATE\".\"state_name\",EXTRACT(year FROM \"LOCATION_RAINFALL\".\"rainfall_recorded_date\") \"year\",EXTRACT(month FROM \"LOCATION_RAINFALL\".\"rainfall_recorded_date\") \"month\",EXTRACT(day FROM \"LOCATION_RAINFALL\".\"rainfall_recorded_date\") \"day\",\"LOCATION_RAINFALL\".\"rainfall_value\" FROM \"npcyf_schema\".\"LOCATION_RAINFALL\" JOIN \"npcyf_schema\".\"DISTRICT\" ON \"LOCATION_RAINFALL\".\"location_id\"=\"DISTRICT\".\"district_id\" JOIN \"npcyf_schema\".\"STATE\" ON \"DISTRICT\".\"state_id\"=\"STATE\".\"state_id\" WHERE \"STATE\".\"state_name\"='bihar' AND \"LOCATION_RAINFALL\".\"location_type\"='DISTRICT' AND \"LOCATION_RAINFALL\".\"rainfall_data_collection_id\"='243' AND \"LOCATION_RAINFALL\".\"rainfall_recorded_year\">='2000' AND \"LOCATION_RAINFALL\".\"rainfall_recorded_year\"<='2022' AND EXTRACT(month FROM \"LOCATION_RAINFALL\".\"rainfall_recorded_date\") IN (5,6,10,11,12,2)) \"rainfall_data\" GROUP BY \"rainfall_data\".\"state_name\",\"rainfall_data\".\"year\"\n",
      "),\n",
      "\"AMXT\" AS (\n",
      "SELECT \"daily_state_temp_AMXT\".\"state_name\",\"daily_state_temp_AMXT\".\"year\",AVG(CASE WHEN \"daily_state_temp_AMXT\".\"month\"=5 THEN \"daily_state_temp_AMXT\".\"avg_temp_per_day\" END) \"AMXT_5\",AVG(CASE WHEN \"daily_state_temp_AMXT\".\"month\"=6 THEN \"daily_state_temp_AMXT\".\"avg_temp_per_day\" END) \"AMXT_6\",AVG(CASE WHEN \"daily_state_temp_AMXT\".\"month\"=7 THEN \"daily_state_temp_AMXT\".\"avg_temp_per_day\" END) \"AMXT_7\" FROM (SELECT \"STATE\".\"state_name\",DATE(\"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") \"date\",EXTRACT(year FROM \"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") \"year\",EXTRACT(month FROM \"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") \"month\",EXTRACT(day FROM \"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") \"day\",AVG(\"LOCATION_TEMPERATURE\".\"temperature_value\") \"avg_temp_per_day\" FROM \"npcyf_schema\".\"LOCATION_TEMPERATURE\" JOIN \"npcyf_schema\".\"DISTRICT\" ON \"LOCATION_TEMPERATURE\".\"location_id\"=\"DISTRICT\".\"district_id\" JOIN \"npcyf_schema\".\"STATE\" ON \"DISTRICT\".\"state_id\"=\"STATE\".\"state_id\" WHERE \"LOCATION_TEMPERATURE\".\"location_type\"='DISTRICT' AND \"STATE\".\"state_name\"='bihar' AND \"LOCATION_TEMPERATURE\".\"temperature_data_collection_id\"=100 AND \"LOCATION_TEMPERATURE\".\"temperature_recorded_year\">='2000' AND \"LOCATION_TEMPERATURE\".\"temperature_recorded_year\"<='2022' AND EXTRACT(month FROM \"LOCATION_TEMPERATURE\".\"temperature_recorded_date\") IN (5,6,7) GROUP BY \"STATE\".\"state_name\",DATE(\"LOCATION_TEMPERATURE\".\"temperature_recorded_date\")) \"daily_state_temp_AMXT\" GROUP BY \"daily_state_temp_AMXT\".\"state_name\",\"daily_state_temp_AMXT\".\"year\"\n",
      ")\n",
      "SELECT \"Weighted Yield\".*,\"TRF\".*,\"AMXT\".* FROM \"Weighted Yield\" JOIN \"TRF\" ON \"Weighted Yield\".\"state_name\"=\"TRF\".\"state_name\" AND \"Weighted Yield\".\"year\"=\"TRF\".\"year\" JOIN \"AMXT\" ON \"Weighted Yield\".\"state_name\"=\"AMXT\".\"state_name\" AND \"Weighted Yield\".\"year\"=\"AMXT\".\"year\"\n"
     ]
    }
   ],
   "source": [
    "# Output the final query\n",
    "print(full_sql)\n",
    "with open(\"Generated_SQL.sql\", \"w\") as file:\n",
    "    file.write(full_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f93fd",
   "metadata": {},
   "source": [
    "## Execute the SQL Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f652d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute SQL and print results ---\n",
    "# Replace with your PostgreSQL credentials\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=\"5433\",\n",
    "        dbname=\"New_Rainfall\",\n",
    "        user=\"postgres\",\n",
    "        password=\"vombolD007@\"\n",
    "    )\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(full_sql)\n",
    "columns = [desc[0] for desc in cursor.description]\n",
    "rows = cursor.fetchall()\n",
    "seen = {}\n",
    "unique_data = []\n",
    "for i, col in enumerate(columns):\n",
    "    if col not in seen:\n",
    "        seen[col] = i  # store the first occurrence index\n",
    "\n",
    "# Keep only unique columns\n",
    "unique_columns = list(seen.keys())\n",
    "unique_indices = list(seen.values())\n",
    "\n",
    "# Filter rows to keep only values for unique columns\n",
    "filtered_rows = [[row[i] for i in unique_indices] for row in rows]\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b51bf5",
   "metadata": {},
   "source": [
    "## Save the result in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bf3299d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>crop_name</th>\n",
       "      <th>season_name</th>\n",
       "      <th>year</th>\n",
       "      <th>Weighted Yield</th>\n",
       "      <th>TRF_5</th>\n",
       "      <th>TRF_6</th>\n",
       "      <th>TRF_10</th>\n",
       "      <th>TRF_11</th>\n",
       "      <th>TRF_12</th>\n",
       "      <th>TRF_2</th>\n",
       "      <th>AMXT_5</th>\n",
       "      <th>AMXT_6</th>\n",
       "      <th>AMXT_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.15</td>\n",
       "      <td>4222.59</td>\n",
       "      <td>11335.75</td>\n",
       "      <td>673.3</td>\n",
       "      <td>12.85</td>\n",
       "      <td>0.59</td>\n",
       "      <td>388.36</td>\n",
       "      <td>35.63</td>\n",
       "      <td>33.67</td>\n",
       "      <td>32.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.07</td>\n",
       "      <td>4764.34</td>\n",
       "      <td>9227.35</td>\n",
       "      <td>8166.88</td>\n",
       "      <td>64.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.39</td>\n",
       "      <td>35.48</td>\n",
       "      <td>32.89</td>\n",
       "      <td>32.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3235.19</td>\n",
       "      <td>5174.78</td>\n",
       "      <td>1580.61</td>\n",
       "      <td>95.84</td>\n",
       "      <td>25.89</td>\n",
       "      <td>443.28</td>\n",
       "      <td>35.48</td>\n",
       "      <td>34.87</td>\n",
       "      <td>33.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2361.18</td>\n",
       "      <td>9753.71</td>\n",
       "      <td>6416.59</td>\n",
       "      <td>6.3</td>\n",
       "      <td>154.62</td>\n",
       "      <td>1576.19</td>\n",
       "      <td>36.91</td>\n",
       "      <td>35.41</td>\n",
       "      <td>33.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2004</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2883.82</td>\n",
       "      <td>9945.22</td>\n",
       "      <td>2787.26</td>\n",
       "      <td>266.11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.04</td>\n",
       "      <td>37.13</td>\n",
       "      <td>34.06</td>\n",
       "      <td>32.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1439.18</td>\n",
       "      <td>4106.28</td>\n",
       "      <td>2044.19</td>\n",
       "      <td>85.85</td>\n",
       "      <td>20.02</td>\n",
       "      <td>443.86</td>\n",
       "      <td>37.25</td>\n",
       "      <td>38.39</td>\n",
       "      <td>32.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2006</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2754.2</td>\n",
       "      <td>7418.72</td>\n",
       "      <td>933.93</td>\n",
       "      <td>78.32</td>\n",
       "      <td>74.6</td>\n",
       "      <td>145.09</td>\n",
       "      <td>35.89</td>\n",
       "      <td>34.72</td>\n",
       "      <td>32.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2007</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2739.76</td>\n",
       "      <td>6520.37</td>\n",
       "      <td>1603.47</td>\n",
       "      <td>659.08</td>\n",
       "      <td>556.1</td>\n",
       "      <td>1058.67</td>\n",
       "      <td>36.53</td>\n",
       "      <td>35.22</td>\n",
       "      <td>32.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2142.08</td>\n",
       "      <td>11159.63</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>39.76</td>\n",
       "      <td>0.99</td>\n",
       "      <td>146.53</td>\n",
       "      <td>36.71</td>\n",
       "      <td>33.18</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2009</td>\n",
       "      <td>2.09</td>\n",
       "      <td>4052.03</td>\n",
       "      <td>2977.36</td>\n",
       "      <td>3946.86</td>\n",
       "      <td>160.87</td>\n",
       "      <td>20.63</td>\n",
       "      <td>17.49</td>\n",
       "      <td>35.83</td>\n",
       "      <td>37.59</td>\n",
       "      <td>33.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2845.15</td>\n",
       "      <td>4315.42</td>\n",
       "      <td>1591.11</td>\n",
       "      <td>301.19</td>\n",
       "      <td>153.38</td>\n",
       "      <td>67.69</td>\n",
       "      <td>37.4</td>\n",
       "      <td>37.21</td>\n",
       "      <td>34.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3835.98</td>\n",
       "      <td>9689.01</td>\n",
       "      <td>511.35</td>\n",
       "      <td>149.85</td>\n",
       "      <td>33.28</td>\n",
       "      <td>452.4</td>\n",
       "      <td>36.29</td>\n",
       "      <td>34.82</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2012</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1541.61</td>\n",
       "      <td>5039.37</td>\n",
       "      <td>1738.64</td>\n",
       "      <td>361.28</td>\n",
       "      <td>2.53</td>\n",
       "      <td>68.05</td>\n",
       "      <td>38.96</td>\n",
       "      <td>37.92</td>\n",
       "      <td>33.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.86</td>\n",
       "      <td>4097.7</td>\n",
       "      <td>7379.19</td>\n",
       "      <td>7777.31</td>\n",
       "      <td>20.47</td>\n",
       "      <td>2.29</td>\n",
       "      <td>854.52</td>\n",
       "      <td>36.29</td>\n",
       "      <td>34.52</td>\n",
       "      <td>33.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4594.49</td>\n",
       "      <td>4800.19</td>\n",
       "      <td>1813.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.46</td>\n",
       "      <td>1225.29</td>\n",
       "      <td>37.7</td>\n",
       "      <td>36.5</td>\n",
       "      <td>33.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2177.96</td>\n",
       "      <td>5415.66</td>\n",
       "      <td>442.12</td>\n",
       "      <td>11.38</td>\n",
       "      <td>41.35</td>\n",
       "      <td>96.15</td>\n",
       "      <td>37.47</td>\n",
       "      <td>36.38</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3788.35</td>\n",
       "      <td>5788.05</td>\n",
       "      <td>2553.64</td>\n",
       "      <td>66.74</td>\n",
       "      <td>4.58</td>\n",
       "      <td>27.38</td>\n",
       "      <td>36.07</td>\n",
       "      <td>35.99</td>\n",
       "      <td>32.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3315.23</td>\n",
       "      <td>3827.09</td>\n",
       "      <td>2729.07</td>\n",
       "      <td>5.28</td>\n",
       "      <td>27.19</td>\n",
       "      <td>10.72</td>\n",
       "      <td>36.7</td>\n",
       "      <td>36.14</td>\n",
       "      <td>32.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2018</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2335.67</td>\n",
       "      <td>4012.73</td>\n",
       "      <td>861.8</td>\n",
       "      <td>5.09</td>\n",
       "      <td>266.73</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.91</td>\n",
       "      <td>36.43</td>\n",
       "      <td>33.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1404.01</td>\n",
       "      <td>3795.59</td>\n",
       "      <td>1292.62</td>\n",
       "      <td>26.29</td>\n",
       "      <td>546.33</td>\n",
       "      <td>1000.35</td>\n",
       "      <td>38.36</td>\n",
       "      <td>37.65</td>\n",
       "      <td>33.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.99</td>\n",
       "      <td>3385.25</td>\n",
       "      <td>11933.74</td>\n",
       "      <td>1383.95</td>\n",
       "      <td>97.26</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1027.16</td>\n",
       "      <td>34.69</td>\n",
       "      <td>33.52</td>\n",
       "      <td>32.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.08</td>\n",
       "      <td>9906.6</td>\n",
       "      <td>12546.1</td>\n",
       "      <td>7731.64</td>\n",
       "      <td>8.78</td>\n",
       "      <td>458.88</td>\n",
       "      <td>18.77</td>\n",
       "      <td>33.38</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bihar</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rabi</td>\n",
       "      <td>2022</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3423.88</td>\n",
       "      <td>7108.44</td>\n",
       "      <td>3318.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.89</td>\n",
       "      <td>1094.5</td>\n",
       "      <td>35.77</td>\n",
       "      <td>35.69</td>\n",
       "      <td>34.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_name crop_name season_name  year Weighted Yield    TRF_5     TRF_6  \\\n",
       "0       bihar     wheat        rabi  2000           2.15  4222.59  11335.75   \n",
       "1       bihar     wheat        rabi  2001           2.07  4764.34   9227.35   \n",
       "2       bihar     wheat        rabi  2002            1.9  3235.19   5174.78   \n",
       "3       bihar     wheat        rabi  2003           1.78  2361.18   9753.71   \n",
       "4       bihar     wheat        rabi  2004           1.61  2883.82   9945.22   \n",
       "5       bihar     wheat        rabi  2005           1.41  1439.18   4106.28   \n",
       "6       bihar     wheat        rabi  2006           2.01   2754.2   7418.72   \n",
       "7       bihar     wheat        rabi  2007           2.34  2739.76   6520.37   \n",
       "8       bihar     wheat        rabi  2008           2.05  2142.08  11159.63   \n",
       "9       bihar     wheat        rabi  2009           2.09  4052.03   2977.36   \n",
       "10      bihar     wheat        rabi  2010           2.43  2845.15   4315.42   \n",
       "11      bihar     wheat        rabi  2011           3.05  3835.98   9689.01   \n",
       "12      bihar     wheat        rabi  2012            2.8  1541.61   5039.37   \n",
       "13      bihar     wheat        rabi  2013           2.86   4097.7   7379.19   \n",
       "14      bihar     wheat        rabi  2014           1.66  4594.49   4800.19   \n",
       "15      bihar     wheat        rabi  2015           2.25  2177.96   5415.66   \n",
       "16      bihar     wheat        rabi  2016           2.85  3788.35   5788.05   \n",
       "17      bihar     wheat        rabi  2017           2.91  3315.23   3827.09   \n",
       "18      bihar     wheat        rabi  2018            3.0  2335.67   4012.73   \n",
       "19      bihar     wheat        rabi  2019            2.6  1404.01   3795.59   \n",
       "20      bihar     wheat        rabi  2020           2.99  3385.25  11933.74   \n",
       "21      bihar     wheat        rabi  2021           3.08   9906.6   12546.1   \n",
       "22      bihar     wheat        rabi  2022           2.95  3423.88   7108.44   \n",
       "\n",
       "     TRF_10  TRF_11  TRF_12    TRF_2 AMXT_5 AMXT_6 AMXT_7  \n",
       "0     673.3   12.85    0.59   388.36  35.63  33.67  32.62  \n",
       "1   8166.88   64.08     0.0    95.39  35.48  32.89  32.39  \n",
       "2   1580.61   95.84   25.89   443.28  35.48  34.87   33.9  \n",
       "3   6416.59     6.3  154.62  1576.19  36.91  35.41  33.11  \n",
       "4   2787.26  266.11     4.0    30.04  37.13  34.06  32.74  \n",
       "5   2044.19   85.85   20.02   443.86  37.25  38.39  32.53  \n",
       "6    933.93   78.32    74.6   145.09  35.89  34.72  32.92  \n",
       "7   1603.47  659.08   556.1  1058.67  36.53  35.22  32.07  \n",
       "8    1412.0   39.76    0.99   146.53  36.71  33.18   32.8  \n",
       "9   3946.86  160.87   20.63    17.49  35.83  37.59  33.71  \n",
       "10  1591.11  301.19  153.38    67.69   37.4  37.21  34.01  \n",
       "11   511.35  149.85   33.28    452.4  36.29  34.82   33.5  \n",
       "12  1738.64  361.28    2.53    68.05  38.96  37.92  33.21  \n",
       "13  7777.31   20.47    2.29   854.52  36.29  34.52  33.71  \n",
       "14  1813.97     0.0   40.46  1225.29   37.7   36.5  33.51  \n",
       "15   442.12   11.38   41.35    96.15  37.47  36.38   33.5  \n",
       "16  2553.64   66.74    4.58    27.38  36.07  35.99  32.46  \n",
       "17  2729.07    5.28   27.19    10.72   36.7  36.14  32.36  \n",
       "18    861.8    5.09  266.73     18.0  35.91  36.43  33.47  \n",
       "19  1292.62   26.29  546.33  1000.35  38.36  37.65  33.45  \n",
       "20  1383.95   97.26    3.77  1027.16  34.69  33.52  32.87  \n",
       "21  7731.64    8.78  458.88    18.77  33.38  33.29  33.19  \n",
       "22  3318.55     0.0   19.89   1094.5  35.77  35.69  34.82  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Combine rows' of value and columns' name and make a dataframe\n",
    "df = pd.DataFrame(filtered_rows, columns=unique_columns)\n",
    "\n",
    "# step1: convert all possible columns to numperic_type and leave rest columns as null\n",
    "df_numeric = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Step 2: Round up numeric values to 2 decimal places\n",
    "df_rounded = np.ceil(df_numeric * 100) / 100\n",
    "df_rounded['year'] = df_rounded['year'].astype(int)\n",
    "\n",
    "# Step 3: Fill back non-numeric (original) columns\n",
    "df_final = df_rounded.combine_first(df)\n",
    "\n",
    "# step 4: save the dataset in a csv file\n",
    "df_final.to_csv('example_Function_Query_Output.csv')\n",
    "df_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
